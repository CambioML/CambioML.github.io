---
title: 'KDD 2024: Conversazione con Amazon'
date: '2025-01-29'
keywords: 'KDD 2024,Modelli di Linguaggio di Grandi Dimensioni,LLM,Generazione Augmentata da Recupero,RAG,ottimizzazione LLM,Amazon,IA specifica per dominio,apprendimento automatico,conferenza'
image: '/images/solutions/kdd-2024-cover.jpeg'
---

![Conferenza KDD 2024](/images/solutions/kdd-2024-cover.jpeg)
_Rachel Hu presenta alla conferenza KDD 2024_

Alla conferenza KDD 2024, [Rachel Hu](https://www.linkedin.com/in/rachelsonghu/), co-fondatrice e CEO di CambioML, ha presentato un tutorial completo su come ottimizzare i Modelli di Linguaggio di Grandi Dimensioni (LLM) per applicazioni specifiche di dominio, insieme ai co-presentatori [José Cassio dos Santos Junior](https://www.linkedin.com/in/jcassiojr/) (Amazon), [Richard Song](https://www.linkedin.com/in/renchu-richard-song-a4099247/) (Epsilla) e [Yunfei Bai](https://www.linkedin.com/in/yunfei-felix-bai-909b861/) (Amazon). La sessione ha fornito approfondimenti dettagliati su due tecniche fondamentali: Generazione Augmentata da Recupero (RAG) e Ottimizzazione degli LLM. Questi metodi sono essenziali per migliorare le prestazioni degli LLM in campi specializzati, consentendo agli sviluppatori di creare modelli più efficaci e accurati, adattati a compiti specifici.

## Comprendere RAG: Espandere le Capacità degli LLM

La Generazione Augmentata da Recupero (RAG) è un approccio potente che estende le capacità degli LLM integrando basi di conoscenza esterne. Questa tecnica consente agli LLM di generare risposte basate su conoscenze specifiche di dominio senza richiedere un ampio riaddestramento. RAG è particolarmente vantaggioso per le organizzazioni che devono sfruttare basi di conoscenza interne o altre risorse specializzate, fornendo un modo per migliorare le prestazioni degli LLM in modo economico ed efficiente in termini di tempo.

## Ottimizzazione: Modelli su Misura per la Precisione

L'Ottimizzazione degli LLM implica la regolazione dei pesi del modello utilizzando dati specifici di dominio, consentendo al modello di apprendere sistematicamente nuove conoscenze complete che non erano incluse durante la fase di pre-addestramento. Questo approccio è essenziale per compiti che richiedono un alto grado di accuratezza ed è particolarmente efficace in domini in cui i modelli di uso generale non riescono a soddisfare le esigenze. L'Ottimizzazione può trasformare un LLM in uno strumento altamente specializzato, capace di eseguire compiti complessi e specifici di dominio con precisione.

![Rachel Hu presenta a KDD](/images/solutions/kdd-2024-rachel.jpeg)

## Combinare RAG e Ottimizzazione per Risultati Ottimali

Il tutorial ha esplorato come la combinazione di RAG e Ottimizzazione possa creare un'architettura robusta per le applicazioni LLM. Integrando questi due approcci, gli sviluppatori possono costruire modelli che non solo accedono alle informazioni esterne più rilevanti, ma apprendono anche dai dati specifici di dominio. Questo approccio ibrido consente la creazione di modelli che sono sia versatili che altamente accurati, capaci di gestire una vasta gamma di compiti specifici di dominio, dalla generazione di testi a scenari complessi di domande e risposte.

## Laboratori Pratici: Applicazioni Pratiche di RAG e Ottimizzazione

Una parte significativa del tutorial di Rachel è stata dedicata a laboratori pratici, dove i partecipanti hanno esplorato tecniche avanzate per ottimizzare le architetture RAG e LLM Ottimizzati. I laboratori hanno coperto una varietà di argomenti, tra cui:

- **Tecniche RAG Avanzate**: Sono state dimostrate strategie di ottimizzazione multi-fase per migliorare l'accuratezza e la rilevanza degli output RAG. Questo includeva ottimizzazione pre-retrieval, retrieval e post-retrieval, così come l'uso innovativo di grafi di conoscenza e analisi multi-documento per un ragionamento più sfumato.

- **Ottimizzazione degli LLM**: I partecipanti hanno partecipato all'ottimizzazione di un piccolo LLM utilizzando dataset specifici di dominio. Il laboratorio ha evidenziato il processo di ottimizzazione continua, integrando feedback sia umano che AI per raggiungere prestazioni superiori in compiti specializzati.

- **Benchmarking e Valutazione**: L'ultimo laboratorio si è concentrato sul confronto delle prestazioni di RAG, Ottimizzazione e del loro approccio combinato attraverso vari compiti. Questo includeva un'analisi dettagliata del ROI per aiutare gli sviluppatori a scegliere il metodo più economico ed efficiente per le loro esigenze specifiche.

![Laboratori KDD 2024](/images/solutions/kdd-2024-labs.jpg)

## Migliori Pratiche per lo Sviluppo di LLM Specifici per Dominio

Il tutorial si è concluso con un insieme di migliori pratiche per implementare RAG e Ottimizzazione in applicazioni del mondo reale. Sottolineando l'importanza di comprendere i compromessi tra la flessibilità di RAG e la precisione dell'Ottimizzazione, i partecipanti sono stati incoraggiati a impegnarsi in esperimenti e benchmarking continui. Questo approccio garantisce che i criteri di prestazione ed economicità siano soddisfatti, consentendo agli sviluppatori di ottimizzare efficacemente la loro architettura LLM per compiti specifici di dominio.

Per una panoramica più dettagliata del contenuto del tutorial e dei laboratori pratici, si prega di fare riferimento a [questo documento](https://dl.acm.org/doi/abs/10.1145/3637528.3671445) e [questa presentazione](https://docs.google.com/presentation/d/18PJctnI-KbABE1El_AifjN_7eoHatuaoN8-2q57xpSw/edit#slide=id.g2f5cc21ff85_5_1096).
