---
title: 'KDD 2024: Discuție cu Amazon'
date: '2025-01-29'
keywords: 'KDD 2024,Modele de Limbaj Mari,LLM,Generare Augmentată prin Recuperare,RAG,finetuning LLM,Amazon,AI specific domeniului,învățare automată,conferință'
image: '/images/solutions/kdd-2024-cover.jpeg'
---

![Conferința KDD 2024](/images/solutions/kdd-2024-cover.jpeg)
_Rachel Hu prezentând la conferința KDD 2024_

La conferința KDD 2024, [Rachel Hu](https://www.linkedin.com/in/rachelsonghu/), co-fondatoare și CEO al CambioML, a prezentat un tutorial cuprinzător despre optimizarea Modelelor de Limbaj Mari (LLMs) pentru aplicații specifice domeniului, alături de co-prezentatori [José Cassio dos Santos Junior](https://www.linkedin.com/in/jcassiojr/) (Amazon), [Richard Song](https://www.linkedin.com/in/renchu-richard-song-a4099247/) (Epsilla) și [Yunfei Bai](https://www.linkedin.com/in/yunfei-felix-bai-909b861/) (Amazon). Sesiunea a oferit perspective aprofundate asupra a două tehnici critice: Generarea Augmentată prin Recuperare (RAG) și Finetuning-ul LLM. Aceste metode sunt esențiale pentru îmbunătățirea performanței LLM-urilor în domenii specializate, permițând dezvoltatorilor să creeze modele mai eficiente și precise, adaptate la sarcini specifice.

## Înțelegerea RAG: Extinderea Capacităților LLM

Generarea Augmentată prin Recuperare (RAG) este o abordare puternică care extinde capacitățile LLM-urilor prin integrarea bazelor de cunoștințe externe. Această tehnică permite LLM-urilor să genereze răspunsuri bazate pe cunoștințe specifice domeniului fără a necesita o reantrenare extinsă. RAG este deosebit de benefică pentru organizațiile care trebuie să valorifice bazele de cunoștințe interne sau alte resurse specializate, oferind o modalitate de a îmbunătăți performanța LLM-urilor într-un mod rentabil și eficient din punct de vedere al timpului.

## Finetuning: Personalizarea Modelului pentru Precizie

Finetuning-ul LLM implică ajustarea greutăților modelului folosind date specifice domeniului, permițând modelului să învețe sistematic cunoștințe noi și cuprinzătoare care nu au fost incluse în faza de pre-antrenare. Această abordare este esențială pentru sarcini care necesită un grad înalt de acuratețe și este deosebit de eficientă în domenii în care modelele de uz general nu reușesc. Finetuning-ul poate transforma un LLM într-un instrument extrem de specializat, capabil să execute sarcini complexe, specifice domeniului, cu precizie.

![Rachel Hu prezentând la KDD](/images/solutions/kdd-2024-rachel.jpeg)

## Combinarea RAG și Finetuning pentru Rezultate Optime

Tutorialul a explorat modul în care combinarea RAG și Finetuning-ului poate crea o arhitectură robustă pentru aplicațiile LLM. Prin integrarea acestor două abordări, dezvoltatorii pot construi modele care nu doar că accesează cele mai relevante informații externe, dar învață și din datele specifice domeniului. Această abordare hibridă permite crearea de modele care sunt atât versatile, cât și extrem de precise, capabile să gestioneze o gamă largă de sarcini specifice domeniului, de la generarea de text la scenarii complexe de întrebări și răspunsuri.

## Laboratoare Practice: Aplicații Practice ale RAG și Finetuning

O parte semnificativă a tutorialului lui Rachel a fost dedicată laboratoarelor practice, unde participanții au explorat tehnici avansate pentru optimizarea arhitecturilor RAG și Finetuned LLM. Laboratoarele au acoperit o varietate de subiecte, inclusiv:

- **Tehnici Avansate RAG**: Strategii de optimizare în mai multe faze au fost demonstrate pentru a îmbunătăți acuratețea și relevanța rezultatelor RAG. Aceasta a inclus optimizarea pre-retrieval, retrieval și post-retrieval, precum și utilizarea inovatoare a grafurilor de cunoștințe și analiza multi-document pentru raționamente mai nuanțate.

- **Finetuning-ul LLM-urilor**: Participanții au fost implicați în finetuning-ul unui mic LLM folosind seturi de date specifice domeniului. Laboratorul a subliniat procesul continuu de finetuning, integrând atât feedback uman, cât și AI pentru a obține o performanță superioară în sarcini specializate.

- **Benchmarking și Evaluare**: Ultimul laborator s-a concentrat pe compararea performanței RAG, Finetuning-ului și a abordării lor combinate în diverse sarcini. Aceasta a inclus o analiză detaliată a ROI pentru a ajuta dezvoltatorii să aleagă cea mai rentabilă și eficientă metodă pentru nevoile lor specifice.

![Laboratoarele KDD 2024](/images/solutions/kdd-2024-labs.jpg)

## Cele Mai Bune Practici pentru Dezvoltarea LLM-urilor Specifice Domeniului

Tutorialul s-a încheiat cu un set de cele mai bune practici pentru implementarea RAG și Finetuning în aplicații din lumea reală. Subliniind importanța înțelegerii compromisurilor între flexibilitatea RAG și precizia Finetuning-ului, participanții au fost încurajați să se angajeze în experimentare continuă și benchmarking. Această abordare asigură că criteriile de performanță și rentabilitate sunt îndeplinite, permițând dezvoltatorilor să optimizeze arhitectura LLM pentru sarcini specifice domeniului în mod eficient.

Pentru o prezentare mai detaliată a conținutului tutorialului și a laboratoarelor practice, vă rugăm să consultați [această lucrare](https://dl.acm.org/doi/pdf/10.1145/3637528.3671445) și [această prezentare](https://docs.google.com/presentation/d/18PJctnI-KbABE1El_AifjN_7eoHatuaoN8-2q57xpSw/edit#slide=id.g2f5cc21ff85_5_1096).
