---
title: 'KDD 2024: Беседа с Amazon'
date: '2025-01-29'
keywords: 'KDD 2024,Большие языковые модели,LLM,Увеличенная генерация с использованием поиска,RAG,Тонкая настройка LLM,Amazon,специфичный для домена ИИ,машинное обучение,конференция'
image: '/images/solutions/kdd-2024-cover.jpeg'
---

![Конференция KDD 2024](/images/solutions/kdd-2024-cover.jpeg)
_Рэйчел Ху выступает на конференции KDD 2024_

На конференции KDD 2024 [Рэйчел Ху](https://www.linkedin.com/in/rachelsonghu/), соучредитель и генеральный директор CambioML, представила обширный учебный курс по оптимизации больших языковых моделей (LLM) для специфичных для домена приложений, вместе с сопредставителями [Жозе Кассио душ Сантуш Жуниор](https://www.linkedin.com/in/jcassiojr/) (Amazon), [Ричардом Соном](https://www.linkedin.com/in/renchu-richard-song-a4099247/) (Epsilla) и [Юнфэем Бай](https://www.linkedin.com/in/yunfei-felix-bai-909b861/) (Amazon). Сессия предоставила глубокие знания о двух критически важных техниках: Увеличенной генерации с использованием поиска (RAG) и тонкой настройке LLM. Эти методы необходимы для повышения производительности LLM в специализированных областях, позволяя разработчикам создавать более эффективные и точные модели, адаптированные к конкретным задачам.

## Понимание RAG: Расширение возможностей LLM

Увеличенная генерация с использованием поиска (RAG) — это мощный подход, который расширяет возможности LLM, интегрируя внешние базы знаний. Эта техника позволяет LLM генерировать ответы на основе специфических знаний в области без необходимости в обширной повторной тренировке. RAG особенно полезен для организаций, которым необходимо использовать внутренние базы знаний или другие специализированные ресурсы, предоставляя способ улучшить производительность LLM экономически эффективно и быстро.

## Тонкая настройка: Настройка моделей для точности

Тонкая настройка LLM включает в себя корректировку весов модели с использованием данных, специфичных для домена, что позволяет модели систематически усваивать новые, обширные знания, которые не были включены в фазу предварительной тренировки. Этот подход необходим для задач, требующих высокой степени точности, и особенно эффективен в областях, где универсальные модели не справляются. Тонкая настройка может преобразовать LLM в высокоспециализированный инструмент, способный выполнять сложные, специфичные для домена задачи с точностью.

![Рэйчел Ху выступает на KDD](/images/solutions/kdd-2024-rachel.jpeg)

## Сочетание RAG и тонкой настройки для оптимальных результатов

Учебный курс исследовал, как сочетание RAG и тонкой настройки может создать надежную архитектуру для приложений LLM. Интегрируя эти два подхода, разработчики могут создавать модели, которые не только получают доступ к наиболее релевантной внешней информации, но и учатся на данных, специфичных для домена. Этот гибридный подход позволяет создавать модели, которые являются как универсальными, так и высокоточными, способными справляться с широким спектром специфичных для домена задач, от генерации текста до сложных сценариев вопрос-ответ.

## Практические лаборатории: Практическое применение RAG и тонкой настройки

Значительная часть учебного курса Рэйчел была посвящена практическим лабораториям, где участники исследовали передовые техники оптимизации архитектур RAG и тонкой настройки LLM. Лаборатории охватывали различные темы, включая:

- **Передовые техники RAG**: Были продемонстрированы многофазные стратегии оптимизации для повышения точности и актуальности выходных данных RAG. Это включало предварительную выборку, выборку и поствыборочную оптимизацию, а также инновационное использование графов знаний и многодокументного анализа для более тонкого рассуждения.

- **Тонкая настройка LLM**: Участники занимались тонкой настройкой небольшой LLM с использованием наборов данных, специфичных для домена. Лаборатория подчеркнула процесс непрерывной тонкой настройки, интегрируя как человеческую, так и ИИ обратную связь для достижения превосходной производительности в специализированных задачах.

- **Бенчмаркинг и оценка**: Последняя лаборатория была сосредоточена на сравнении производительности RAG, тонкой настройки и их комбинированного подхода по различным задачам. Это включало детальный анализ ROI, чтобы помочь разработчикам выбрать наиболее экономически эффективный и эффективный метод для их конкретных нужд.

![Лаборатории KDD 2024](/images/solutions/kdd-2024-labs.jpg)

## Лучшие практики для разработки LLM, специфичных для домена

Учебный курс завершился набором лучших практик для реализации RAG и тонкой настройки в реальных приложениях. Подчеркивая важность понимания компромиссов между гибкостью RAG и точностью тонкой настройки, участникам было предложено продолжать эксперименты и бенчмаркинг. Этот подход гарантирует, что критерии производительности и экономической эффективности будут соблюдены, позволяя разработчикам эффективно оптимизировать свою архитектуру LLM для специфичных для домена задач.

Для более подробного обзора содержания учебного курса и практических лабораторий, пожалуйста, обратитесь к [этой статье](https://dl.acm.org/doi/pdf/10.1145/3637528.3671445) и [этой презентации](https://docs.google.com/presentation/d/18PJctnI-KbABE1El_AifjN_7eoHatuaoN8-2q57xpSw/edit#slide=id.g2f5cc21ff85_5_1096).
