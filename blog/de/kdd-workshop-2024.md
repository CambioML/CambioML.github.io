---
title: 'KDD 2024: Gespräch mit Amazon'
date: '2025-01-29'
keywords: 'KDD 2024,Große Sprachmodelle,LLM,Retrieval Augmented Generation,RAG,LLM Feinabstimmung,Amazon,domänenspezifische KI,maschinelles Lernen,Konferenz'
image: '/images/solutions/kdd-2024-cover.jpeg'
---

![KDD 2024 Konferenz](/images/solutions/kdd-2024-cover.jpeg)
_Rachel Hu präsentiert auf der KDD 2024 Konferenz_

Auf der KDD 2024 Konferenz präsentierte [Rachel Hu](https://www.linkedin.com/in/rachelsonghu/), Mitbegründerin und CEO von CambioML, ein umfassendes Tutorial zur Optimierung großer Sprachmodelle (LLMs) für domänenspezifische Anwendungen, zusammen mit den Mitpräsentatoren [José Cassio dos Santos Junior](https://www.linkedin.com/in/jcassiojr/) (Amazon), [Richard Song](https://www.linkedin.com/in/renchu-richard-song-a4099247/) (Epsilla) und [Yunfei Bai](https://www.linkedin.com/in/yunfei-felix-bai-909b861/) (Amazon). Die Sitzung bot tiefgehende Einblicke in zwei kritische Techniken: Retrieval Augmented Generation (RAG) und LLM Feinabstimmung. Diese Methoden sind entscheidend, um die Leistung von LLMs in spezialisierten Bereichen zu verbessern und Entwicklern zu ermöglichen, effektivere und genauere Modelle zu erstellen, die auf spezifische Aufgaben zugeschnitten sind.

## Verständnis von RAG: Erweiterung der LLM-Fähigkeiten

Retrieval Augmented Generation (RAG) ist ein leistungsstarker Ansatz, der die Fähigkeiten von LLMs erweitert, indem externe Wissensdatenbanken integriert werden. Diese Technik ermöglicht es LLMs, Antworten basierend auf spezifischem Fachwissen zu generieren, ohne umfangreiche Neutrainings zu erfordern. RAG ist besonders vorteilhaft für Organisationen, die interne Wissensdatenbanken oder andere spezialisierte Ressourcen nutzen müssen, und bietet eine Möglichkeit, die Leistung von LLMs kosteneffektiv und zeiteffizient zu verbessern.

## Feinabstimmung: Modelle für Präzision anpassen

Die Feinabstimmung von LLMs umfasst die Anpassung der Gewichte des Modells mithilfe von domänenspezifischen Daten, sodass das Modell systematisch neues, umfassendes Wissen erlernen kann, das während der Vortrainingsphase nicht enthalten war. Dieser Ansatz ist entscheidend für Aufgaben, die ein hohes Maß an Genauigkeit erfordern, und ist besonders effektiv in Bereichen, in denen allgemeine Modelle versagen. Die Feinabstimmung kann ein LLM in ein hochspezialisiertes Werkzeug verwandeln, das in der Lage ist, komplexe, domänenspezifische Aufgaben mit Präzision auszuführen.

![Rachel Hu präsentiert auf KDD](/images/solutions/kdd-2024-rachel.jpeg)

## Kombination von RAG und Feinabstimmung für optimale Ergebnisse

Das Tutorial untersuchte, wie die Kombination von RAG und Feinabstimmung eine robuste Architektur für LLM-Anwendungen schaffen kann. Durch die Integration dieser beiden Ansätze können Entwickler Modelle erstellen, die nicht nur auf die relevantesten externen Informationen zugreifen, sondern auch aus domänenspezifischen Daten lernen. Dieser hybride Ansatz ermöglicht die Erstellung von Modellen, die sowohl vielseitig als auch hochgenau sind und in der Lage sind, eine Vielzahl von domänenspezifischen Aufgaben zu bewältigen, von der Textgenerierung bis hin zu komplexen Frage-Antwort-Szenarien.

## Praktische Labore: Anwendungsbeispiele für RAG und Feinabstimmung

Ein wesentlicher Teil von Rachels Tutorial war den praktischen Laboren gewidmet, in denen die Teilnehmer fortgeschrittene Techniken zur Optimierung von RAG und feinabgestimmten LLM-Architekturen erkundeten. Die Labore deckten eine Vielzahl von Themen ab, darunter:

- **Fortgeschrittene RAG-Techniken**: Mehrphasige Optimierungsstrategien wurden demonstriert, um die Genauigkeit und Relevanz der RAG-Ausgaben zu verbessern. Dazu gehörten Vorab-Retrieval, Retrieval und Nach-Retrieval-Optimierung sowie die innovative Nutzung von Wissensgraphen und Multi-Dokumenten-Analyse für nuancierteres Denken.

- **Feinabstimmung von LLMs**: Die Teilnehmer engagierten sich in der Feinabstimmung eines kleinen LLMs mithilfe von domänenspezifischen Datensätzen. Das Labor hob den kontinuierlichen Feinabstimmungsprozess hervor, der sowohl menschliches als auch KI-Feedback integriert, um eine überlegene Leistung in spezialisierten Aufgaben zu erreichen.

- **Benchmarking und Evaluierung**: Das letzte Labor konzentrierte sich auf den Vergleich der Leistung von RAG, Feinabstimmung und ihrem kombinierten Ansatz über verschiedene Aufgaben hinweg. Dies umfasste eine detaillierte ROI-Analyse, um Entwicklern zu helfen, die kosteneffektivste und effizienteste Methode für ihre spezifischen Bedürfnisse auszuwählen.

![KDD 2024 Labore](/images/solutions/kdd-2024-labs.jpg)

## Best Practices für die Entwicklung domänenspezifischer LLMs

Das Tutorial schloss mit einer Reihe von Best Practices für die Implementierung von RAG und Feinabstimmung in realen Anwendungen. Dabei wurde die Bedeutung des Verständnisses der Kompromisse zwischen der Flexibilität von RAG und der Präzision der Feinabstimmung betont. Die Teilnehmer wurden ermutigt, kontinuierlich zu experimentieren und zu benchmarken. Dieser Ansatz stellt sicher, dass die Kriterien für Leistung und Kosteneffektivität erfüllt werden, sodass Entwickler ihre LLM-Architektur effektiv für domänenspezifische Aufgaben optimieren können.

Für einen detaillierteren Überblick über die Inhalte des Tutorials und die praktischen Labore verweisen wir auf [dieses Papier](https://dl.acm.org/doi/abs/10.1145/3637528.3671445) und [diese Präsentation](https://docs.google.com/presentation/d/18PJctnI-KbABE1El_AifjN_7eoHatuaoN8-2q57xpSw/edit#slide=id.g2f5cc21ff85_5_1096).
